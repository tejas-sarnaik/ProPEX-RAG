<h1 align="center">PROPEX-RAG: Enhanced GraphRAG using Prompt Driven Prompt Execution</h1>

[<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com)

[<img align="center" src="https://img.shields.io/badge/arXiv-ProPEX--RAG-b31b1b" />](https://arxiv.org/abs/<your_id>)
[<img align="center" src="https://img.shields.io/badge/ğŸ¤— Dataset-ProPEX--RAG-yellow" />](https://huggingface.co/datasets/tejas-sarnaik/ProPEX-RAG/tree/main)
[<img align="center" src="https://img.shields.io/badge/GitHub-ProPEX--RAG-blue" />](https://github.com/tejas-sarnaik/ProPEX-RAG.git)

### ProPEX-RAG is a prompt-driven, entity-guided RAG framework that emphasizes the role of prompt design in improving retrieval and reasoning across large knowledge graphs.

Our approach unifies symbolic graph construction with prompt-aware online retrieval, enabling precise entity extraction, fact filtering, and multi-hop passage re-ranking.

This design achieves high performance on complex QA tasks while maintaining scalability and efficiency, offering a practical and interpretable alternative to existing graph-based RAG systems.

<p align="center">
  <img align="center" src="https://github.com/tejasssarnaik/ProPexRAG/blob/main/images/ProPexRAG_Diagram_final_1.jpg" />
</p>
<p align="center">
  <b>Figure 1:</b> ProPEX-RAG methodology.
</p>

#### Check out our papers to learn more:

* [**PROPEX-RAG: Enhanced GraphRAG using Prompt Driven Prompt Execution**](https://arxiv.org/abs/<your_id>) [PReMI '25].

----

### Environment Setup

1. Create conda environment:
   ```bash
   conda create -n propexrag python=3.10 -y
   conda activate propexrag

   pip install -r requirements.txt

   ```

2. Configure Models and API Keys
   - Replace the default models in config.py with your custom models (if needed)

## ğŸš€ Quick Start

### 1. Setup Environment
Clone the repository and install dependencies:

```bash
git clone https://github.com/tejas-sarnaik/ProPEX-RAG.git
cd ProPEX-RAG
```

### 2. Configure Models
Edit config.py to plug in your desired provider.
```bash
LLM_PROVIDER = "openai"
OPENAI_API_KEY = "<your_openai_api_key>"
OPENAI_ENDPOINT = "<your_openai_endpoint_url>"
OPENAI_DEPLOYMENT_NAME = "<your_openai_model>"
OPENAI_EMBEDDING_DEPLOYMENT = "<your_openai_embedding_model>"
```

```bash
For local/offline models (e.g., LLaMA, HuggingFace):
LLM_PROVIDER = "llama"
LOCAL_MODEL_PATH = "/path/to/llama-60b-instruct-or-other"
LOCAL_EMBEDDING_MODEL = "NV-Embed-v2(7B) or other"
LOCAL_EMBEDDING_DEVICE = "cuda"
```
ğŸ‘‰ Simply switch LLM_PROVIDER between openai, llama, vllm, or huggingface depending on your setup.

### 3. Build the Knowledge Graph
Run the main orchestrator to construct the symbolic knowledge graph:
```bash
python main.py
```
This step extracts entities, fact triples, and builds the graph the knowledge garph.

### 4. Run Retrieval & QA
To run retrieval and answer questions:
```bash
python rag_ppr_retriever.py --question "When did Maradona sign with Barcelona?"
```
Retrieval Process: rag_ppr_retriever.py
QA Pipeline: qa_pipeline.py

### 5. Example Demo
ProPEX-RAG follows a **prompt-driven, entity-guided pipeline** with the following steps:
1. **Entity Extraction** â†’ Identifies key entities from the query  
   *Example:* `Messi, Barcelona, Copa del Rey`
2. **Graph Traversal** â†’ Expands with aliases and traverses neighbors using Personalized PageRank (PPR)
3. **Fact Filtering** â†’ Keeps only the most relevant fact triples  
   *Example:* `Messi â†’ compared_to â†’ Maradona, Maradona â†’ signed_by â†’ Barcelona`
4. **Evidence Projection** â†’ Projects entity scores back onto passages
5. **Reranking** â†’ Reorders Top-k passages using entity overlap, title boosts, and coherent multi-hop paths
6. **Answer Synthesis** â†’ Prompts over the selected passages and extracts the final answer with provenance
---

ğŸ“Œ **Illustrative Example**
- **Question:**  
  *When was Maradona signed by Barcelona?*
- **Extracted Entities:**  
  `{Messi, Maradona, Barcelona}`
- **Graph Traversal:**  
  `Messi â†’ compared_to â†’ Maradona â†’ signed_by â†’ Barcelona`
- **Reranked Evidence:**  
  Passage **Pâ‚ (FC Barcelona)** surfaced to the top
- **Synthesized Answer:**  
  **June 1982**

## Code Structure

# ğŸ“‚ ProPEX-RAG Project Structur
```bash
ProPEX-RAG/
â”œâ”€â”€ ğŸ“„ README.md                   # Project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                     # License file
â”œâ”€â”€ ğŸ“„ requirements.txt            # Python dependencies
â”œâ”€â”€ ğŸ“„ config.py                   # Configuration settings
â”‚
â”œâ”€â”€ ğŸ Core Components
â”‚   â”œâ”€â”€ main.py                    # Main pipeline orchestrator
â”‚   â”œâ”€â”€ knowledge_graph_core.py    # Knowledge graph construction
â”‚   â”œâ”€â”€ facts_triplet_entity_processor.py # Entity and triplet processing
â”‚   â”œâ”€â”€ qa_pipeline.py             # Question-answering pipeline
â”‚   â”œâ”€â”€ rag_ppr_retriever.py       # Personalized PageRank retrieval
â”‚   â””â”€â”€ run_extract.py             # Entity/triple extraction runner
â”‚
â”œâ”€â”€ ğŸ“ prompts/                    # Prompt templates
â”‚   â”œâ”€â”€ prompts.py                 # Core prompt templates
â”‚   â”œâ”€â”€ hotpot_prompt.py           # HotpotQA specific prompts
â”‚   â”œâ”€â”€ sampleqa_prompt.py         # Sample QA prompts
â”‚   â””â”€â”€ triple_filter_prompt.py    # Triple filtering prompts
â”‚
â”œâ”€â”€ ğŸ“ datasets/                   # Sample data
â”‚   â”œâ”€â”€ sample_database_corpus.json # Sample corpus data
â”‚   â””â”€â”€ sample_database_qa.json    # Sample QA pairs
â”‚
â”œâ”€â”€ ğŸ“ images/                     # Documentation assets
â”‚   â””â”€â”€ ProPexRAG_Diagram_final_1.jpg # Architecture diagram
â”‚
â”œâ”€â”€ ğŸ“ output_directory/           # Processing outputs
â”‚   â”œâ”€â”€ output_entity_facts_triplets/ # Processed entities & triplets
â”‚   â”‚   â”œâ”€â”€ 1_passage_data_with_ner_triples.json
â”‚   â”‚   â”œâ”€â”€ filtered_fact_triples_all.json
â”‚   â”‚   â””â”€â”€ processing_checkpoint.json
â”‚   â”œâ”€â”€ retrievals/                # Retrieval results
â”‚   â”œâ”€â”€ debug_trace_final/         # Debug traces
â”‚   â””â”€â”€ final_debug_trace/         # Final debug outputs
â”‚
â”œâ”€â”€ ğŸ“ debug_trace_final/          # Debug information
â”œâ”€â”€ ğŸ“ final_output_dataset/       # Final processed datasets
â””â”€â”€ ğŸ“ __pycache__/                # Python cache files


```

## Contact

Questions or issues? File an issue or contact 
[Tejas Sarnaik](mailto:tejassarnaik2120@gmail.com)

## Citation

If you find this work useful, please consider citing our papers:

### ProPEX-RAG
```
```

## TODO:

- [x] Add support for more embedding models
- [x] Add support for embedding endpoints
- [ ] Add support for vector database integration

Please feel free to open an issue or PR if you have any questions or suggestions.
